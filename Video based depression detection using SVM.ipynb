{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gabor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xIBuDuETSyLlmN1XGZ_pcTg1vAvu9hFz",
      "authorship_tag": "ABX9TyP2BbQ57TVHziNaWIHve0zd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nish714/Video-based-depression-detection-using-Support-Vector-Machine-SVM-/blob/main/Video%20based%20depression%20detection%20using%20SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItERRyfiYnSw",
        "outputId": "4f595f01-282a-4539-9dca-16b7f2b2e8ee"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61ERv3WOgFu-"
      },
      "source": [
        "import cv2 \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os     # mkdir command\n",
        "import glob  # read multiple image sequentially from a folder\n",
        "from google.colab.patches import cv2_imshow  #show image in colab\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#Loading the trained Haar classifier (Load the cascade)\n",
        "face_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/Colab Notebooks/haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/Colab Notebooks/haarcascade_eye.xml')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPxse6JezQiS"
      },
      "source": [
        "#defining a function to return cropped faces with 2 eyes\n",
        "def get_cropped_image(path):\n",
        "        img = cv2.imread(path)\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "        for (x,y,w,h) in faces:\n",
        "            roi_gray = gray[y:y+h, x:x+w]\n",
        "            roi_color = img[y:y+h, x:x+w]   #roi = region of interest\n",
        "            return roi_color  #returns image if face visible else returns NONE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOWgChZzJRjR"
      },
      "source": [
        "def get_filtered_image(path) :\n",
        "      hfimg = {}\n",
        "      imig = cv2.imread(path)\n",
        "      imig = cv2.cvtColor(imig, cv2.COLOR_BGR2GRAY) \n",
        "      imig = cv2.resize(imig,(160,160)) \n",
        "      \n",
        "      ksize = 5  \n",
        "      sigma = 3  \n",
        "      gamma=0.9  \n",
        "      phi = 0.8 \n",
        "\n",
        "      orientation = [ 0,25,45,70,90,123,146,158.] \n",
        "      scale =[ 3.0,3.1,3.2,3.3,3.4] \n",
        "      n=1\n",
        "      for i in orientation:\n",
        "        for j in scale:\n",
        "          theta = i\n",
        "          lamda = j\n",
        "          kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, phi, ktype=cv2.CV_32F) \n",
        "          hfimg[n] = cv2.filter2D(imig,cv2.CV_8UC3,kernel)\n",
        "          if n ==1:\n",
        "           hfinal = hfimg[n]\n",
        "          else:\n",
        "           hfinal = cv2.add(hfinal,hfimg[n])\n",
        "          kernel_resized = cv2.resize(kernel,(160,160))\n",
        "          n+=1 \n",
        "          \n",
        "      return hfinal    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmuZZaImspfI"
      },
      "source": [
        "#Path define\n",
        "path_to_data = \"/content/drive/MyDrive/Colab Notebooks/Depression classifier/dataset/\"\n",
        "path_to_cr_data = \"/content/drive/MyDrive/Colab Notebooks/Depression classifier/dataset/cropped/\"\n",
        "path_to_gabor_data = \"/content/drive/MyDrive/Colab Notebooks/Depression classifier/dataset/filtered/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhneZ7DEumSF"
      },
      "source": [
        "#stores path of all the individual sub-folders in a python list\n",
        "img_dirs = [] # list of dataset sub-folder\n",
        "for entry in os.scandir(path_to_data): #goto all sub directoris within dataset folder\n",
        "    if entry.is_dir():\n",
        "        img_dirs.append(entry.path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1Vf7RoRv-xh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "f6471abf-c16b-464f-9c0a-3dca2d4d726b"
      },
      "source": [
        "#create cropped folder if it doesn't exist in the given directory\n",
        "import shutil\n",
        "if os.path.exists(path_to_cr_data):  #check if cropped folder exist\n",
        "     shutil.rmtree(path_to_cr_data) #remove if exist \n",
        "     #(helpful in multiple run scenario i.e., to use the cropped folder again n again without residual previous inputs)\n",
        "os.mkdir(path_to_cr_data) #create cropped folder\n",
        "os.mkdir(path_to_gabor_data) #folder to store filtered images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-504e6abb706d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m      \u001b[0;31m#(helpful in multiple run scenario i.e., to use the cropped folder again n again without residual previous inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_cr_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#create cropped folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_gabor_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#folder to store filtered images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/MyDrive/Colab Notebooks/Depression classifier/dataset/filtered/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDoSUKFZxcgF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "e5e7bd61-8f6a-4fc0-960a-a9e6b6cb8eb8"
      },
      "source": [
        "#Cropped Images\n",
        "cropped_image_dirs = [] #python list to store cropped folder path for all 3 emotion\n",
        "emotion_file_names_dict = {}  #key-value pair dictionary where key is emotion name and value are the cropped images\n",
        "\n",
        "for img_dir in img_dirs: #iterate through the image directories\n",
        "    count = 1\n",
        "    emotion_name = img_dir.split('/')[-1]   #[-1] gives last element from the list\n",
        "    #img_dir list string split at '/' and taking the last element will give individual folder name\n",
        "    #--> print(emotion_name)\n",
        "    emotion_file_names_dict[emotion_name] = []\n",
        "    \n",
        "    for entry in os.scandir(img_dir): #iterate thru all the image in the sub folder\n",
        "        roi_color = get_cropped_image(entry.path)\n",
        "        if roi_color is not None:  #sth is returned from the get_cropped_image_if_2_eyes() function\n",
        "            cropped_folder = path_to_cr_data + emotion_name  #creates sub-folders in the cropped folder for 3 emotions\n",
        "            if not os.path.exists(cropped_folder):\n",
        "                os.makedirs(cropped_folder)\n",
        "                cropped_image_dirs.append(cropped_folder)\n",
        "                 \n",
        "            cropped_file_name = emotion_name + str(count) + \".png\"   #name of the file\n",
        "            cropped_file_path = cropped_folder + \"/\" + cropped_file_name  #path of the file \n",
        "            \n",
        "            cv2.imwrite(cropped_file_path, roi_color)\n",
        "            emotion_file_names_dict[emotion_name].append(cropped_file_path)\n",
        "            count += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d98fe43df90c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#iterate thru all the image in the sub folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mroi_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cropped_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mroi_color\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#sth is returned from the get_cropped_image_if_2_eyes() function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mcropped_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_cr_data\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0memotion_name\u001b[0m  \u001b[0;31m#creates sub-folders in the cropped folder for 3 emotions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-93a4883f0a68>\u001b[0m in \u001b[0;36mget_cropped_image\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_cropped_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y17bF7GLIN4R"
      },
      "source": [
        "fimg_dirs = [] # list of dataset sub-folder\n",
        "for entry in os.scandir(path_to_cr_data): #goto all sub directoris within dataset folder\n",
        "    if entry.is_dir():\n",
        "        fimg_dirs.append(entry.path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLttQ71NsKae"
      },
      "source": [
        "#Gabor Filtered image\n",
        "filtered_image_dirs = [] #python list to store filtered folder path for all 3 emotion\n",
        "filtered_emotion_file_names_dict = {}  #key-value pair dictionary where key is emotion name and value are the filtered images\n",
        "\n",
        "for fimg_dir in fimg_dirs: #iterate through the filtered image directories\n",
        "    count = 1\n",
        "    emotion_name = fimg_dir.split('/')[-1]   #[-1] gives last element from the list\n",
        "    #img_dir list string split at '/' and taking the last element will give individual folder name\n",
        "    #--> print(emotion_name)\n",
        "    filtered_emotion_file_names_dict[emotion_name] = []\n",
        "    \n",
        "    for entry in os.scandir(fimg_dir): #iterate thru all the image in the sub folder\n",
        "        roi_filtered_ = get_filtered_image(entry.path)\n",
        "        if roi_filtered_ is not None:  #sth is returned from the get_cropped_image_if_2_eyes() function\n",
        "            filtered_folder = path_to_gabor_data + emotion_name  #creates sub-folders in the cropped folder for 3 emotions\n",
        "            if not os.path.exists(filtered_folder):\n",
        "                os.makedirs(filtered_folder)\n",
        "                filtered_image_dirs.append(filtered_folder)\n",
        "                               \n",
        "            filtered_file_name = emotion_name + str(count) + \".png\"   #name of the file\n",
        "            filtered_file_path = filtered_folder + \"/\" + filtered_file_name  #path of the file \n",
        "            \n",
        "            cv2.imwrite(filtered_file_path, roi_filtered_)\n",
        "            filtered_emotion_file_names_dict[emotion_name].append(filtered_file_path)\n",
        "            count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4l9OGGNsxsZ"
      },
      "source": [
        "#PCA Reduction\n",
        "pca=PCA(n_components=30)\n",
        "\n",
        "path = glob.glob('/content/drive/MyDrive/Colab Notebooks/Depression classifier/dataset/filtered/disgust/*')\n",
        "x=0\n",
        "dt = {}\n",
        "key = []\n",
        "value = []\n",
        "for img in path:\n",
        "  imig = cv2.imread(img)\n",
        "  imig = cv2.cvtColor(imig, cv2.COLOR_BGR2GRAY) \n",
        "  (means, stds) = cv2.meanStdDev(imig)\n",
        "  mean = cv2.mean(imig)\n",
        "  raw = imig.flatten()\n",
        "  data = (raw-means[0])/stds[0]\n",
        "  key.append(x)\n",
        "  value.append(data)\n",
        "  x+=1\n",
        "  \n",
        "dt = dict(zip(key,value))\n",
        "df = pd.DataFrame(data = dt).T\n",
        "pca.fit(df)\n",
        "x_pca=pca.transform(df)\n",
        "featureSet = x_pca.T\n",
        "fs = pd.DataFrame(featureSet)\n",
        "fs['class'] = 3\n",
        "fs.to_csv('disgust.csv',index = False)\n",
        "\n",
        "path = glob.glob('/content/drive/MyDrive/Colab Notebooks/Depression classifier/dataset/filtered/contempt/*')\n",
        "x=0\n",
        "dt = {}\n",
        "key = []\n",
        "value = []\n",
        "for img in path:\n",
        "  imig = cv2.imread(img)\n",
        "  imig = cv2.cvtColor(imig, cv2.COLOR_BGR2GRAY) \n",
        "  (means, stds) = cv2.meanStdDev(imig)\n",
        "  mean = cv2.mean(imig)\n",
        "  raw = imig.flatten()\n",
        "  data = (raw-means[0])/stds[0]\n",
        "  key.append(x)\n",
        "  value.append(data)\n",
        "  x+=1\n",
        "\n",
        "dt = dict(zip(key,value))\n",
        "df = pd.DataFrame(data = dt).T\n",
        "pca.fit(df)\n",
        "x_pca=pca.transform(df)\n",
        "featureSet = x_pca.T\n",
        "fs = pd.DataFrame(featureSet)\n",
        "fs['class'] = 2\n",
        "fs.to_csv('contempt.csv',index = False)\n",
        "\n",
        "path = glob.glob('/content/drive/MyDrive/Colab Notebooks/Depression classifier/dataset/filtered/happy/*')\n",
        "x=0\n",
        "dt = {}\n",
        "key = []\n",
        "value = []\n",
        "for img in path:\n",
        "  imig = cv2.imread(img)\n",
        "  imig = cv2.cvtColor(imig, cv2.COLOR_BGR2GRAY) \n",
        "  (means, stds) = cv2.meanStdDev(imig)\n",
        "  mean = cv2.mean(imig)\n",
        "  raw = imig.flatten()\n",
        "  data = (raw-means[0])/stds[0]\n",
        "  key.append(x)\n",
        "  value.append(data)\n",
        "  x+=1\n",
        "  \n",
        "dt = dict(zip(key,value))\n",
        "df = pd.DataFrame(data = dt).T\n",
        "pca.fit(df)\n",
        "x_pca=pca.transform(df)\n",
        "featureSet = x_pca.T\n",
        "fs = pd.DataFrame(featureSet)\n",
        "fs['class'] = 1\n",
        "fs.to_csv('happy.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6zeNEdA1I05"
      },
      "source": [
        "df = pd.concat( map(pd.read_csv, ['happy.csv', 'contempt.csv','disgust.csv']), ignore_index=True)\n",
        "df.to_csv('trainFeature.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_0zWTFTlkRw"
      },
      "source": [
        "path_to_test_data = \"/content/drive/MyDrive/Colab Notebooks/Depression classifier/dataset/testing\"\n",
        "path_to_testcr_data = \"/content/drive/MyDrive/Colab Notebooks/Depression classifier/dataset/testing/cropped/\"\n",
        "path_to_gabor_data = \"/content/drive/MyDrive/Colab Notebooks/Depression classifier/dataset/testing/gabor/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gM707Nwlkjr"
      },
      "source": [
        "#create cropped folder if it doesn't exist in the given directory\n",
        "import shutil\n",
        "if os.path.exists(path_to_testcr_data):  #check if cropped folder exist\n",
        "     shutil.rmtree(path_to_testcr_data) #remove if exist \n",
        "os.mkdir(path_to_testcr_data) #create test cropped folder\n",
        "os.mkdir(path_to_gabor_data) #create test filter folder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzgbP3fwo6OR"
      },
      "source": [
        "#Cropped Test Images\n",
        "#Testing======\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/Colab Notebooks/Depression classifier/dataset/testing/Ses03M_script01_3 .mp4')\n",
        "count = 1\n",
        "while True: \n",
        "    _, img = cap.read() # _ is the variable to hold flag(if the img is captured properly then true)\n",
        "    gray = cv2.cvtColor( img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "    for (x, y, w, h) in faces:\n",
        "       roi_gray = gray[y:y+h, x:x+w]\n",
        "       if roi_gray is not None:              \n",
        "          test_file_name = str(count) + \".png\"   #name of the file\n",
        "          test_file_path = path_to_testcr_data + \"/\" + test_file_name  #path of the file \n",
        "          cv2.imwrite(test_file_path, roi_gray)\n",
        "          count += 1    \n",
        "cap.release() # Release the VideoCapture object\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5eM0Myt1JSY"
      },
      "source": [
        "#Filter test images\n",
        "path = glob.glob('/content/drive/MyDrive/Colab Notebooks/Depression classifier/dataset/testing/cropped/*')\n",
        "count = 1\n",
        "for img in path:\n",
        "      hfimg = {}\n",
        "      imig = cv2.imread(img)\n",
        "      imig = cv2.cvtColor(imig, cv2.COLOR_BGR2GRAY) \n",
        "      imig = cv2.resize(imig,(160,160)) \n",
        "      \n",
        "      ksize = 5  \n",
        "      sigma = 3  \n",
        "      gamma=0.9  \n",
        "      phi = 0.8 \n",
        "\n",
        "      orientation = [0,25,45,70,90,123,146,158] \n",
        "      scale =[3.0,3.1,3.2,3.3,4.4] \n",
        "      n=1\n",
        "      for i in orientation:\n",
        "        for j in scale:\n",
        "          theta = i\n",
        "          lamda = j\n",
        "          kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, phi, ktype=cv2.CV_32F) \n",
        "          hfimg[n] = cv2.filter2D(imig,cv2.CV_8UC3,kernel)\n",
        "          if n ==1:\n",
        "           hfinal = hfimg[n]\n",
        "          else:\n",
        "           hfinal = cv2.add(hfinal,hfimg[n])\n",
        "          kernel_resized = cv2.resize(kernel,(160,160))\n",
        "          n+=1 \n",
        "          \n",
        "      if hfinal is not None:\n",
        "        filtered_file_name = str(count) + \".png\"   #name of the file\n",
        "        filtered_file_path = path_to_gabor_data + \"/\" + filtered_file_name  #path of the file \n",
        "        cv2.imwrite(filtered_file_path, hfinal)\n",
        "        count += 1  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4TM63w91sWv"
      },
      "source": [
        "pca=PCA(n_components=30)\n",
        "\n",
        "path = glob.glob('/content/drive/MyDrive/Colab Notebooks/Depression classifier/dataset/testing/gabor/*')\n",
        "x=0\n",
        "dt = {}\n",
        "key = []\n",
        "value = []\n",
        "for img in path:\n",
        "  imig = cv2.imread(img)\n",
        "  imig = cv2.cvtColor(imig, cv2.COLOR_BGR2GRAY) \n",
        "  (means, stds) = cv2.meanStdDev(imig)\n",
        "  mean = cv2.mean(imig)\n",
        "  raw = imig.flatten()\n",
        "  data = (raw-means[0])/stds[0]\n",
        "  key.append(x)\n",
        "  value.append(data)\n",
        "  x+=1\n",
        "  \n",
        "dt = dict(zip(key,value))\n",
        "df = pd.DataFrame(data = dt).T\n",
        "pca.fit(df)\n",
        "x_pca=pca.transform(df)\n",
        "featureSet = x_pca\n",
        "fs = pd.DataFrame(featureSet)\n",
        "fs.to_csv('testFeatureSet.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tcCl6c_5u7G"
      },
      "source": [
        "data = pd.read_csv('trainFeature.csv')\n",
        "X=data.drop('class',axis=1)\n",
        "Y=data['class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HBrpzKm2ow1"
      },
      "source": [
        "model = SVC(C=10)\n",
        "model.fit(X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiFAmskI2pBg"
      },
      "source": [
        "test = pd.read_csv('testFeatureSet.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2RcCnvm8yWh"
      },
      "source": [
        "p = model.predict(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7oCaRW8AIb3"
      },
      "source": [
        "test['class'] = p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOcDHG4nAPRJ"
      },
      "source": [
        "test.to_csv('prediction.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}